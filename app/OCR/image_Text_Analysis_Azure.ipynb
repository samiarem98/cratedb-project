{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Documentation: Image and Text Processing Pipeline with Azure OCR, OpenAI, and CrateDB\n",
    "\n",
    "1. Overview\n",
    "\n",
    "This script provides a complete pipeline for processing documents and images, extracting meaningful text and keywords, storing data in CrateDB, and using Azure OCR and OpenAI's API for generating embeddings and chatbot responses. The key functionality includes:\n",
    "\n",
    "Extracting images from PDFs\n",
    "\n",
    "Performing OCR (Optical Character Recognition) using Azure's Computer Vision API\n",
    "\n",
    "Generating embeddings for text using OpenAI's API\n",
    "\n",
    "Storing extracted data in CrateDB\n",
    "\n",
    "Using KNN (K-Nearest Neighbors) search in CrateDB to find relevant context for a user question\n",
    "\n",
    "Generating responses to user queries based on document content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from rake_nltk import Rake\n",
    "from crate import client\n",
    "import fitz  \n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "AZURE_ENDPOINT = os.environ['AZURE_ENDPOINT']\n",
    "AZURE_SUBSCRIPTION_KEY = os.environ['AZURE_SUBSCRIPTION_KEY']\n",
    "CRATEDB_PW = os.environ['CRATEDB_PW']\n",
    "CRATEDB_URI = os.environ['CRATEDB_URI']\n",
    "USERNAME = \"admin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "computervision_client = ComputerVisionClient(AZURE_ENDPOINT, CognitiveServicesCredentials(AZURE_SUBSCRIPTION_KEY))\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract images from a PDF using PyMuPDF\n",
    "def extract_images_with_pymupdf(pdf_path, output_folder):\n",
    "    \"\"\"Extract images from a PDF using PyMuPDF and save them.\"\"\"\n",
    "    pdf_document = fitz.open(pdf_path)  # Open the PDF document\n",
    "    image_count = 0\n",
    "\n",
    "    for page_number in range(len(pdf_document)):\n",
    "        page = pdf_document[page_number]  # Get the page\n",
    "        image_list = page.get_images(full=True)  # Get list of images on the page\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]  # Image reference number\n",
    "            base_image = pdf_document.extract_image(xref)  # Extract the image\n",
    "            image_bytes = base_image[\"image\"]  # Get the image bytes\n",
    "            image_ext = base_image[\"ext\"]  # Get the image file extension (e.g., png, jpeg)\n",
    "\n",
    "            # Create an image file name and save the image\n",
    "            image_filename = f\"page_{page_number + 1}_img_{img_index + 1}.{image_ext}\"\n",
    "            image_path = os.path.join(output_folder, image_filename)\n",
    "            with open(image_path, \"wb\") as image_file:\n",
    "                image_file.write(image_bytes)\n",
    "\n",
    "            print(f\"Saved image: {image_filename}\")\n",
    "            image_count += 1\n",
    "\n",
    "    pdf_document.close()  # Close the PDF document\n",
    "    return image_count\n",
    "\n",
    "#CrateDB connection setup\n",
    "def get_crate_connection():\n",
    "    \"\"\"\n",
    "    Establish a connection to CrateDB.\n",
    "    \"\"\"\n",
    "    return client.connect(CRATEDB_URI, username=USERNAME, password=CRATEDB_PW, verify_ssl_cert=True)\n",
    "\n",
    "Function to generate tags\n",
    "def generate_tags(keywords):\n",
    "    \"\"\"\n",
    "    Generate tags from the most significant keywords.\n",
    "    \"\"\"\n",
    "    return keywords[:5] if len(keywords) > 5 else keywords\n",
    "\n",
    "# Function to extract the page number from the image name\n",
    "def extract_page_number(image_name):\n",
    "    \"\"\"\n",
    "    Extract the page number from the image file name.\n",
    "    Assumes file names follow the pattern 'page_<number>*.png'.\n",
    "    \"\"\"\n",
    "    match = re.search(r'page_(\\d+)', image_name)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Return the number after 'page_'\n",
    "    return None  # Return None if no match is found\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    \"\"\"Cleans the extracted text.\"\"\"\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "# Function to extract keywords using RAKE\n",
    "def extract_keywords(text):\n",
    "    \"\"\"Extract keywords using RAKE.\"\"\"\n",
    "    rake = Rake()\n",
    "    rake.extract_keywords_from_text(text)\n",
    "    return rake.get_ranked_phrases()\n",
    "\n",
    "# Function to filter and prioritize keywords\n",
    "def filter_and_prioritize_keywords(keywords):\n",
    "    \"\"\"Filters and prioritizes keywords, removing punctuation and non-relevant words.\"\"\"\n",
    "    filtered_keywords = {\n",
    "        keyword.strip().lower()\n",
    "        for keyword in keywords\n",
    "        if len(keyword.split()) >= 2 and len(keyword) > 5 and\n",
    "        not any(punc in keyword for punc in [\"(\", \")\", \"+\", \"-\", \"=\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\", \"the\", \"yes\", \"no\"]) \n",
    "    }\n",
    "    return sorted(filtered_keywords, key=lambda k: -len(k))  # Sort by length (longer phrases first))\n",
    "\n",
    "# Function to analyze an image with Azure OCR and extract keywords\n",
    "def analyze_image_with_azure(image_path):\n",
    "    \"\"\"Extract text and refine keywords.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        ocr_result = computervision_client.read_in_stream(image_file, raw=True)\n",
    "    operation_location = ocr_result.headers[\"Operation-Location\"]\n",
    "    operation_id = operation_location.split(\"/\")[-1]\n",
    "\n",
    "    while True:\n",
    "        result = computervision_client.get_read_result(operation_id)\n",
    "        if result.status not in [\"notStarted\", \"running\"]:\n",
    "            break\n",
    "        print(\"Waiting for Azure OCR results...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    if result.status == \"succeeded\":\n",
    "        extracted_text = \"\"\n",
    "        for page in result.analyze_result.read_results:\n",
    "            for line in page.lines:\n",
    "                extracted_text += line.text + \" \"\n",
    "        clean_extracted_text = clean_text(extracted_text)\n",
    "        raw_keywords = extract_keywords(clean_extracted_text)\n",
    "\n",
    "        # If no keywords, attempt single-word extraction\n",
    "        if not raw_keywords:\n",
    "            raw_keywords = clean_extracted_text.split()\n",
    "\n",
    "        # Filter and prioritize keywords (without important_terms)\n",
    "        final_keywords = filter_and_prioritize_keywords(raw_keywords)\n",
    "        return clean_extracted_text, final_keywords\n",
    "\n",
    "    return \"\", []\n",
    "# Function to generate image description\n",
    "def generate_image_description(image_path):\n",
    "    \"\"\"\n",
    "    Generate a description for an image using Azure's Computer Vision API or a similar service.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            description_result = computervision_client.describe_image_in_stream(image_file)\n",
    "\n",
    "        if description_result.captions:\n",
    "            # Select the caption with the highest confidence\n",
    "            description = max(description_result.captions, key=lambda c: c.confidence).text\n",
    "            print(f\"Generated image description: {description}\")\n",
    "            return description\n",
    "        else:\n",
    "            print(\"No description could be generated for the image.\")\n",
    "            return \"No description available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating image description for {image_path}: {e}\")\n",
    "        return \"Error generating description.\"\n",
    "\n",
    "# Function to store data in CrateDB\n",
    "def store_data_to_cratedb(page_number, image_name, extracted_text, keywords, tags, embedding_text, embedding_keywords, image_description):\n",
    "    \"\"\"\n",
    "    Store extracted text, keywords, tags, embeddings, and image description into CrateDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_crate_connection()\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Ensure the table exists\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS text_data (\n",
    "            page_number INT,\n",
    "            image_name TEXT,\n",
    "            text TEXT,\n",
    "            keywords TEXT,\n",
    "            tags TEXT,\n",
    "            embedding_text FLOAT_VECTOR(1536),  -- Embedding for the text\n",
    "            embedding_keywords FLOAT_VECTOR(1536),\n",
    "            image_description TEXT  -- Description of the image\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        conn.commit()\n",
    "\n",
    "        # Insert data\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO text_data (page_number, image_name, text, keywords, tags, embedding_text, embedding_keywords, image_description)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?);\n",
    "        \"\"\"\n",
    "        cursor.execute(\n",
    "            insert_query,\n",
    "            (\n",
    "                page_number,\n",
    "                image_name,\n",
    "                extracted_text,\n",
    "                \", \".join(keywords),  # Convert keywords to a single string\n",
    "                \", \".join(tags),  # Convert tags to a single string\n",
    "                embedding_text,  # Embedding vector for the text\n",
    "                embedding_keywords,  # Embedding vector for the keywords\n",
    "                image_description  # Description of the image\n",
    "            ),\n",
    "        )\n",
    "        conn.commit()\n",
    "        print(f\"Data from {image_name} stored successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error storing data to CrateDB: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting images from PDF...\n",
      "Saved image: page_1_img_1.png\n",
      "Saved image: page_4_img_1.png\n",
      "Saved image: page_5_img_1.png\n",
      "Saved image: page_6_img_1.png\n",
      "Saved image: page_6_img_2.png\n",
      "Saved image: page_6_img_3.png\n",
      "Saved image: page_8_img_1.png\n",
      "Saved image: page_9_img_1.png\n",
      "Saved image: page_10_img_1.png\n",
      "Saved image: page_10_img_2.png\n",
      "Saved image: page_11_img_1.png\n",
      "Saved image: page_12_img_1.png\n",
      "Saved image: page_13_img_1.png\n",
      "Saved image: page_13_img_2.png\n",
      "Saved image: page_14_img_1.png\n",
      "Saved image: page_16_img_1.png\n",
      "Saved image: page_16_img_2.png\n",
      "Saved image: page_17_img_1.png\n",
      "Saved image: page_17_img_2.png\n",
      "Saved image: page_19_img_1.png\n",
      "Saved image: page_21_img_1.png\n",
      "Saved image: page_21_img_2.png\n",
      "Saved image: page_24_img_1.png\n",
      "Saved image: page_24_img_2.jpeg\n",
      "Saved image: page_25_img_1.png\n",
      "Saved image: page_32_img_1.png\n",
      "Saved image: page_33_img_1.png\n",
      "Saved image: page_34_img_1.png\n",
      "Saved image: page_38_img_1.png\n",
      "Saved image: page_40_img_1.png\n",
      "Saved image: page_41_img_1.png\n",
      "Saved image: page_42_img_1.png\n",
      "Saved image: page_47_img_1.png\n",
      "Saved image: page_47_img_2.png\n",
      "Saved image: page_47_img_3.png\n",
      "Saved image: page_49_img_1.png\n",
      "Saved image: page_49_img_2.png\n",
      "Saved image: page_54_img_1.png\n",
      "Saved image: page_54_img_2.png\n",
      "Saved image: page_55_img_1.png\n",
      "Saved image: page_55_img_2.png\n",
      "Saved image: page_56_img_1.png\n",
      "Saved image: page_59_img_1.png\n",
      "Saved image: page_60_img_1.png\n",
      "Saved image: page_60_img_2.png\n",
      "Saved image: page_60_img_3.png\n",
      "Saved image: page_62_img_1.png\n",
      "Saved image: page_62_img_2.png\n",
      "Saved image: page_63_img_1.png\n",
      "Saved image: page_64_img_1.png\n",
      "Saved image: page_64_img_2.png\n",
      "Saved image: page_65_img_1.png\n",
      "Extracted 52 images from the PDF.\n",
      "\n",
      "Processing image: marketecture.png\n",
      "Could not extract page number from marketecture.png. Skipping this image.\n",
      "\n",
      "Processing image: page_10_img_1.png\n",
      "Waiting for Azure OCR results...\n",
      "Extracted Text from page_10_img_1.png (Page 10):\n",
      "Access mode Visible to user Unity Catalog Supported dropdown support languages Single user Always Yes Python, SQL, Scala, R Shared Always (Premium plan required) Yes Python (DBR 11.1+), SQL No isolation Can be hidden by enforcing user isolation in the admin Python, SQL, shared console or configuring account-level settings No Scala, R Only shown for existing clusters without access modes Custom (i.e. legacy cluster modes, Standard or High No Python, SQL, Concurrency); not an option for creating new clusters. Scala, R\n",
      "Extracted Keywords from page_10_img_1.png (Page 10):\n",
      "existing clusters without access modes custom, enforcing user isolation, creating new clusters, premium plan required, legacy cluster modes, access mode visible, configuring account, r shared always, level settings, shared console, admin python\n",
      "Generated Tags: existing clusters without access modes custom, enforcing user isolation, creating new clusters, premium plan required, legacy cluster modes\n",
      "Generated image description: table\n",
      "Error storing data to CrateDB: could not translate host name \"cratedb\" to address: No such host is known. \n",
      "\n",
      "\n",
      "Processing image: page_10_img_2.png\n",
      "Waiting for Azure OCR results...\n",
      "Extracted Text from page_10_img_2.png (Page 10):\n",
      "Worker type Min workers Max workers Standard_DS3_v2 14 GB Memory, 4 Cores Iv 2 8 Spot instances Driver type Same as worker 14 GB Memory, 4 Cores v Enable autoscaling\n",
      "Extracted Keywords from page_10_img_2.png (Page 10):\n",
      "\n",
      "Generated Tags: \n",
      "Generated image description: graphical user interface, text, application\n",
      "Error storing data to CrateDB: could not translate host name \"cratedb\" to address: No such host is known. \n",
      "\n",
      "\n",
      "Processing image: page_11_img_1.png\n",
      "Waiting for Azure OCR results...\n",
      "Extracted Text from page_11_img_1.png (Page 11):\n",
      "Summary 1 Driver 14 GB Memory, 4 Cores Runtime 13.3.x-scala2.12 Standard_DS3_v2 0.75 DBU/h\n",
      "Extracted Keywords from page_11_img_1.png (Page 11):\n",
      "\n",
      "Generated Tags: \n",
      "Generated image description: graphical user interface, text, application\n",
      "Error storing data to CrateDB: could not translate host name \"cratedb\" to address: No such host is known. \n",
      "\n",
      "\n",
      "Processing image: page_12_img_1.png\n",
      "Waiting for Azure OCR results...\n",
      "Extracted Text from page_12_img_1.png (Page 12):\n",
      "No Permissions Can Attach To Can Restart Can Manage Attach notebook V View Spark Ul, cluster metrics, driver logs V Start, restart, terminate V Edit V Attach library Resize V Change permissions\n",
      "Extracted Keywords from page_12_img_1.png (Page 12):\n",
      "terminate v edit v attach library resize v change permissions, driver logs v start, cluster metrics\n",
      "Generated Tags: terminate v edit v attach library resize v change permissions, driver logs v start, cluster metrics\n",
      "Generated image description: table\n",
      "Error storing data to CrateDB: could not translate host name \"cratedb\" to address: No such host is known. \n",
      "\n",
      "\n",
      "Processing image: page_13_img_1.png\n",
      "Waiting for Azure OCR results...\n",
      "Extracted Text from page_13_img_1.png (Page 13):\n",
      "Utility Description Example fs Manipulates the Databricks filesystem (DBFS) from the console dbutils.fs.ls() Provides utilities for leveraging secrets within secrets notebooks dbutils. secrets.get() notebook Utilities for the control flow of a notebook dbutils.notebook.run() widgets Methods to create and get bound value of input widgets inside notebooks dbutils.widget. text() jobs Utilities for leveraging jobs features dbutils.jobs.taskValues. set()\n",
      "Extracted Keywords from page_13_img_1.png (Page 13):\n",
      "utility description example fs manipulates, leveraging jobs features dbutils, databricks filesystem, get bound value, console dbutils, control flow\n",
      "Generated Tags: utility description example fs manipulates, leveraging jobs features dbutils, databricks filesystem, get bound value, console dbutils\n",
      "Generated image description: graphical user interface, application, table\n",
      "Error storing data to CrateDB: could not translate host name \"cratedb\" to address: No such host is known. \n",
      "\n",
      "\n",
      "Processing image: page_13_img_2.png\n",
      "Waiting for Azure OCR results...\n",
      "Extracted Text from page_13_img_2.png (Page 13):\n",
      "ID Course 1 1 Databricks 2 2 Azure 3 3 Big_Data\n",
      "Extracted Keywords from page_13_img_2.png (Page 13):\n",
      "\n",
      "Generated Tags: \n",
      "Generated image description: table\n",
      "Error storing data to CrateDB: could not translate host name \"cratedb\" to address: No such host is known. \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Skipping this image.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Delay between operations\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn unexpected error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main processing workflow\n",
    "try:\n",
    "    pdf_path = r\"../../data/Databricks.pdf\"\n",
    "    #edit the output folder (where the extracted images from pdf will be located!)\n",
    "    output_folder = r\"C:\\Users\\sami.arem\\OneDrive - Solita Oy\\Desktop\\extracted_images\"\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Step 1: Extract images from PDF\n",
    "    print(\"Extracting images from PDF...\")\n",
    "    image_count = extract_images_with_pymupdf(pdf_path, output_folder)\n",
    "    print(f\"Extracted {image_count} images from the PDF.\")\n",
    "\n",
    "    # Step 2: Process each image\n",
    "    for image_file in sorted(os.listdir(output_folder)):\n",
    "        if image_file.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            image_path = os.path.join(output_folder, image_file)\n",
    "            try:\n",
    "                print(f\"\\nProcessing image: {image_file}\")\n",
    "\n",
    "                # Extract page number from the image name\n",
    "                page_number = extract_page_number(image_file)\n",
    "                if page_number is None:\n",
    "                    print(f\"Could not extract page number from {image_file}. Skipping this image.\")\n",
    "                    continue\n",
    "\n",
    "                # Extract text and keywords\n",
    "                extracted_text, keywords = analyze_image_with_azure(image_path)\n",
    "\n",
    "                # Print extracted text and keywords\n",
    "                print(f\"Extracted Text from {image_file} (Page {page_number}):\\n{extracted_text}\")\n",
    "                print(f\"Extracted Keywords from {image_file} (Page {page_number}):\\n{', '.join(keywords)}\")\n",
    "\n",
    "                # Generate tags\n",
    "                tags = generate_tags(keywords)\n",
    "                print(f\"Generated Tags: {', '.join(tags)}\")\n",
    "\n",
    "                # Generate embeddings\n",
    "                embedding_text = embeddings.embed_query(extracted_text)  # Embedding for the text\n",
    "                keyword_string = \", \".join(keywords) if keywords else \"\"\n",
    "                embedding_keywords = embeddings.embed_query(keyword_string)  # Embedding for the keywords\n",
    "\n",
    "                # Generate image description\n",
    "                image_description = generate_image_description(image_path)\n",
    "\n",
    "                # Store data in CrateDB\n",
    "                store_data_to_cratedb(\n",
    "                    page_number,\n",
    "                    image_file,\n",
    "                    extracted_text,\n",
    "                    keywords,\n",
    "                    tags,\n",
    "                    embedding_text,\n",
    "                    embedding_keywords,\n",
    "                    image_description\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing {image_file}: {e}. Skipping this image.\")\n",
    "            time.sleep(5)  # Delay between operations\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot's response:\n",
      " The Unity Catalog in Databricks is a feature that provides access management controls for users/groups, Metastore access controls, and compute resources within workspaces. It assists in user access data, automated auditing, management controls, lineage monitoring, data discovery and classification, and sharing of various data components such as files, tables, notebooks, model registry, and feature store.\n",
      "\n",
      "In essence, the Unity Catalog in Databricks serves as a centralized platform that facilitates efficient data management, access control, auditing, and sharing functionalities across different data components within the workspace environment.\n",
      "\n",
      "The information regarding the Unity Catalog was extracted from pages 6 and 62.\n"
     ]
    }
   ],
   "source": [
    "my_question = \"What is Unity catalog?\"\n",
    "query_embedding = embeddings.embed_query(my_question)  # Generate embedding for the question\n",
    "\n",
    "# KNN query to include page numbers in the result\n",
    "knn_query = \"\"\"\n",
    "    SELECT text, page_number\n",
    "    FROM text_data\n",
    "    WHERE knn_match(embedding_text, ?, 4)\n",
    "    ORDER BY _score DESC\n",
    "    LIMIT 4\n",
    "\"\"\"\n",
    "\n",
    "# Connect to CrateDB and execute the query\n",
    "documents = []\n",
    "page_numbers = []\n",
    "\n",
    "try:\n",
    "    conn = get_crate_connection()  # Get CrateDB connection\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Execute the KNN query with the embedding\n",
    "    cursor.execute(knn_query, [query_embedding])\n",
    "    \n",
    "    # Fetch and process the results\n",
    "    for record in cursor.fetchall():\n",
    "        documents.append(record[0])  # Assuming 'text' is the relevant field to return\n",
    "        page_numbers.append(record[1])  # Extract the page number\n",
    "    \n",
    "    # Combine documents and page numbers to generate context\n",
    "    context = \"\"\n",
    "    for doc, page_number in zip(documents, page_numbers):\n",
    "        context += f\"Page {page_number}:\\n{doc}\\n\\n\"\n",
    "    \n",
    "    # Define the system prompt with instructions and context\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an expert in Databricks and are answering a user's question based on the following context extracted from multiple sources (images of a document). \n",
    "    Your task is to synthesize information from ALL the available images to answer the user's question comprehensively. \n",
    "\n",
    "    Key Requirements:\n",
    "    - Synthesize and combine ALL relevant information from the images that pertains to the question.\n",
    "    - Your response should provide a clear, detailed and concise answer to the user's question.\n",
    "    - At the END of your response, include a note specifying the page numbers where the referenced information was extracted. \n",
    "      For example, 'The information was extracted from pages X, Y, and Z.'\n",
    "    - if the provided context does not contain relevant information, respond only with: \"I don't know.\"\n",
    "    - If the query is not about Databricks, respond with: \"I don't know.\"\n",
    "\n",
    "    Context (summarized from all images):\n",
    "    {context}\n",
    "\n",
    "    User's Question:\n",
    "    {my_question}\n",
    "    \"\"\"\n",
    "\n",
    "    # Set your OpenAI API key here (ensure you have the key set correctly in your environment variables)\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')  # Ensure this is set in your environment\n",
    "\n",
    "    # Create the chat completion\n",
    "    chat_completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # Specify the model to use\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": my_question},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Extract and print the response\n",
    "    response = chat_completion['choices'][0]['message']['content']\n",
    "    print(\"Chatbot's response:\\n\", response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while querying CrateDB: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
